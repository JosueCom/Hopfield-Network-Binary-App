from __future__ import print_function
import random

# import layer and neuron classes that I previouly wrote
from layer import Layer

# Neu = neurons
# Pat = patterns
# Num = numbers
# Lay = layer
# Dataset = data set
# Der = partial derivative / derivative
# Sqrt = square/squared
# Funct = function
# WRT = with respect to

inputOutputDataset = [
                        #[0,1,0,1,0],
                        #[1,1,0,0,0],
                        #[0,0,0,1,1],
                        #[1,0,0,0,0,1,0,0, 0,0,0,1,0,1,1,1, 1,1,1,1,0,0,0,0, 1,0,0,0,1,0,1,0, 1,1,0,1,1,0,0,0, 1,0,0,1,1,0,1,1, 0,0,0,1,0,0,0,0, 1,1,0,1,0,0,0,0, 0,1,0,1,1,1,0,0, 1,1,1,1,0,1,0,1],
                        #[0,1,0,0,0,0,1,1, 1,1,0,1,0,0,0,0, 1,0,0,1,0,0,0,1, 0,0,1,1,0,0,0,0, 0,0,1,1,0,0,0,0, 0,0,0,1,1,1,0,1, 1,1,0,0,0,1,0,0, 1,0,1,1,1,0,1,1, 0,0,1,1,0,0,1,0, 0,1,0,1,1,1,1,0],
                        #[0,0,1,1,0,0,0,1, 1,1,1,1,1,1,0,1, 0,1,0,0,0,1,0,0, 1,0,0,1,1,0,1,0, 1,0,1,0,0,0,0,1, 0,1,1,1,0,0,1,1, 0,1,1,0,1,1,1,0, 1,1,1,0,1,0,1,0, 1,0,1,0,1,1,0,0, 1,0,0,1,1,0,1,0],
                        #[0,0,1,0,1,0,0,1, 0,1,1,0,1,1,1,0, 1,1,0,1,1,0,1,0, 1,1,0,0,0,1,0,1, 1,0,0,1,1,0,0,0, 1,1,1,0,1,0,1,1, 0,1,1,1,0,0,0,1, 0,1,0,0,0,0,0,0, 0,1,1,0,1,1,0,0, 1,0,1,0,1,1,0,0],
                        #[0,0,0,1,0,1,0,1, 0,0,0,1,0,0,1,0, 1,1,0,0,1,0,0,1, 0,0,1,1,1,1,0,1, 0,1,0,0,1,1,1,0, 0,1,1,0,0,1,1,1, 1,1,1,0,1,0,1,1, 0,0,0,1,1,0,1,1, 1,1,0,0,1,1,0,0, 0,0,0,0,1,0,1,0],
                        #[1,0,1,1,1,1,1,0, 0,0,1,0,1,1,0,0, 1,1,0,1,0,0,1,1, 1,0,0,1,1,1,0,0, 0,0,0,0,1,0,1,1, 1,1,1,1,1,1,1,1, 0,0,0,1,0,0,1,1, 0,1,0,1,1,0,1,0, 1,0,1,1,1,1,0,0, 1,1,1,1,1,0,0,0],
                        #[1,1,0,0,0,1,1,0, 0,1,0,0,0,1,0,1, 1,0,0,0,0,0,1,1, 1,0,1,0,0,1,0,1, 0,1,1,0,1,0,1, 1,0,1,0,1,1,1,0,1, 1,1,1,0,1,0,0,1, 1,1,1,1,1,0,1,0, 0,0,1,1,0,0,0,0, 0,0,0,0,0,1,0,1],
                        #[0,0,0,1,1,1,1,0, 0,1,1,0,1,1,0,0, 1,0,0,1,1,0,1,0, 0,1,0,1,1,0,0,0, 0,1,1,1,1,1,0,1, 1,0,1,0,1,0,0,0, 0,1,1,1,1,0,1,0, 0,1,0,0,0,1,1,1, 1,1,1,0,0,0,1,0, 0,1,0,0,1,0,0,1],
                        [0,1,1,0,1,0,0,0,1,0,0,0,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,0,0,0,0,0,1,0,1,1,1,1,0,0,0,1,0,1,0,0,1,0,0,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,0,0,0,1,1,0,0,1,0,1,1,0,1,1,1,0,0,1,1,1,1,0,0,0,0,0,1,1,0,0,0,0,1,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,0,0,0,0,1,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,1,0,1,0,1,1,0,0,1,0,0,0,0,0,1,1,1,1,1,1,0,0,1,1,1,1,0,1,0,1,0,0,1,0,0,0,0,1,1,0,0,0,1,1,1,0,1,0,1,0,1,0,0,0,1,1,0,1,1,1,0,0,0,1,0,0,0,1,1,0,1,1,0,1,0,0,0,0,0,1,1,0,1,0,0,0,1,1,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,1,1,1,0,0,0,1,0,0,1,1,0,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,0,1,0,0,1,0,0,1,1,1,0,0,1,1,1,1,0,0,1,1,0,1,0,1,1,1,0,1,0,0,1,0,1,0,1,0,0,0,1,0,0,1,0,0,0,1,0,1,1,1,0,0,0,0,1,1,1,0,0,0,0,1,0,1,0,0,0,0,1,0,1,1,0,1,0,1,0,1,0,0,0,0,1,1,0,1,0,1,1,0,1,1,0,1,0,1,0,1,1,0,1,0,1,0,1,1,0,0,0,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,1,0,1,0,1,1,0,1,1,1,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0,1,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,1,0,0,0,1,0,1,0,0,1,1,1,1,0,1,1,1,1,0,0,1,1,1,0,0,0,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,0,1,1,1,0,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,0,1,0,1,0,0,1,0,0,1,1,1,0,0,1,1,0,1,1,0,0,0,0,1,0,1,0,1,0,0,1,1,1,0,0,0,0,1,1,0,1,0,1,0,0,1,1,1,0,1,0,1,1,0,1,1,1,1,0,1,0,1,0,1,1,0,0,0,1,1,0,0,0,0,1,0,0,0,1,1,1,0,1,0,0,1,0,1,1,1,0,0,1,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,0,1,0,0,0,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,1,1,0,0,1,0,1,0,1,0,1,1,0,0,1,1,0,0,1,1,0,1,0,1,1,1,1,1,1,0,0,0,1,0,0,0,0,0,1,0,1,0,0,1,1,1,0,0,0,0,0,0,1,0,0,0,1,1,0,1,0,0,1,1,1,1,0,1,1,1,0,0,1,1,0,0,1,0,0,1,1,1,1,0,0,1,0,1,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,1,1,1,0],
                        [1,0,0,0,0,1,1,1,0,0,0,1,0,1,1,1,0,1,1,0,0,1,0,0,1,1,1,1,1,0,1,1,1,1,1,0,0,1,0,1,1,0,0,0,0,0,1,0,1,1,1,0,0,0,1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,1,0,1,1,1,1,0,0,1,0,0,1,0,1,1,1,0,1,0,1,0,0,1,1,0,0,0,0,1,1,0,1,1,1,0,0,0,0,0,1,0,0,0,1,0,1,1,1,1,0,0,1,1,1,0,0,1,0,1,0,1,0,1,1,1,0,1,1,0,0,1,0,0,1,0,0,1,1,1,0,0,1,1,1,0,0,0,1,0,0,0,1,1,0,1,0,1,0,0,0,0,0,1,0,1,1,1,1,1,1,0,0,1,1,0,0,1,1,1,1,1,1,0,1,0,1,1,0,0,0,1,0,1,1,0,0,0,0,0,0,1,1,0,1,1,0,1,1,0,0,1,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1,1,1,0,0,1,1,0,1,0,0,0,1,0,1,1,1,1,1,1,0,1,1,0,0,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,1,0,0,1,1,1,0,0,0,0,0,0,1,1,0,1,1,1,1,0,0,1,0,1,0,1,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,1,0,0,0,1,0,1,0,0,1,0,1,0,0,0,0,1,1,1,0,0,0,0,1,0,1,0,0,1,1,1,1,1,1,1,1,0,1,1,1,0,1,0,1,0,0,1,1,1,1,0,0,0,1,1,0,1,1,0,0,0,0,0,1,1,1,1,1,0,1,1,1,0,0,0,0,0,1,0,1,0,0,1,1,1,0,0,0,0,1,1,1,0,0,1,1,0,0,0,1,0,1,0,0,1,0,0,0,1,0,1,0,0,1,1,1,0,1,1,1,1,0,0,0,1,1,1,0,0,1,0,0,0,0,0,1,0,1,1,1,0,0,0,1,1,0,0,1,0,1,0,0,0,0,0,1,1,1,1,1,1,0,0,0,1,0,0,0,1,1,1,0,0,1,0,0,1,1,1,0,1,0,1,0,1,0,1,1,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,1,1,0,0,0,1,1,0,1,1,1,1,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,1,0,0,0,1,0,1,1,1,1,0,0,1,0,0,1,1,0,0,0,1,0,0,1,1,0,0,1,0,0,0,1,1,1,0,0,0,0,0,0,1,1,0,0,0,1,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,1,0,1,0,0,1,0,1,0,0,0,0,1,1,0,0,0,1,1,1,0,1,0,0,1,1,1,0,1,0,0,0,1,1,0,0,0,1,0,0,0,1,0,1,0,1,1,0,1,1,1,0,0,0,1,1,1,1,1,1,1,0,0,1,0,1,0,1,0,1,0,1,1,0,0,0,1,0,0,1,1,1,0,1,1,1,1,0,0,0,0,0,1,1,0,0,1,0,1,0,1,0,1,1,0,0,0,0,0,1,0,1,0,0,1,0,1,0,0,1,0,0,1,1,1,0,0,1,0,0,1,1,0,0,0,1,0,0,1,1,0,0,0,0,0,0,1,0,1,0,0,0,1,1,1,1,1,1,1,1,0],
                        [0,0,0,0,1,1,1,0,0,0,1,1,0,1,0,1,1,0,0,0,0,0,0,0,1,0,0,1,1,1,1,1,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,1,1,1,1,0,0,1,0,0,0,0,1,1,0,1,0,0,0,0,1,0,0,0,1,1,0,0,1,1,1,0,1,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,1,0,0,1,0,1,0,1,1,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,1,1,1,1,1,1,0,1,1,0,0,0,1,1,0,0,1,1,1,1,1,0,0,0,1,0,0,1,0,1,1,0,1,0,0,1,1,1,1,1,0,1,0,0,1,1,1,0,0,1,1,0,0,1,0,1,1,1,1,1,1,0,1,0,0,1,0,0,1,1,1,0,1,1,0,1,0,1,1,0,0,1,1,0,1,1,1,0,0,0,1,0,0,1,0,1,0,1,1,1,1,1,0,1,1,0,1,1,0,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,0,1,1,1,0,0,1,1,1,1,0,1,1,0,1,1,0,1,1,0,0,1,0,0,1,0,1,1,1,0,0,1,1,0,0,0,1,0,1,1,0,0,1,1,1,1,0,0,1,0,0,0,1,0,1,0,1,0,1,1,0,0,0,1,0,1,0,0,1,0,1,1,1,1,1,1,0,0,0,1,1,1,1,0,1,1,0,0,1,0,1,1,0,1,1,1,1,0,0,1,0,1,1,0,0,1,0,1,1,0,0,0,1,0,0,1,1,0,1,0,1,0,0,1,1,1,0,0,0,1,1,1,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,0,1,1,0,1,1,1,0,1,1,0,1,1,0,1,1,1,1,0,1,1,1,1,1,0,1,0,0,1,0,1,1,0,1,1,1,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,1,1,1,0,0,1,1,0,1,1,0,1,0,1,1,0,0,1,0,0,1,0,0,0,0,0,0,1,0,0,1,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,0,0,1,1,0,0,1,1,0,1,1,0,0,0,1,1,0,0,1,1,0,1,0,1,1,1,0,0,1,0,1,0,0,1,0,1,1,1,0,0,1,0,0,1,1,1,1,1,1,0,0,1,0,0,0,1,0,1,1,0,0,0,0,0,1,0,1,1,0,1,1,0,1,1,1,1,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1,1,0,1,0,1,1,1,1,1,0,0,1,0,0,1,0,0,0,0,0,1,1,1,0,1,1,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0,1,0,0,1,0,1,1,0,0,0,1,1,0,1,1,1,1,1,0,0,0,1,0,1,0,0,1,0,1,1,1,0,0,1,0,0,0,0,1,0,0,1,0,1,1,1,0,0,0,1,0,1,0,1,1,0,0,1,0,1,0,1,0,1,1,1,1,0,1,0,0,0,0,1,1,1,0,1,0,0,1,0,1,0,0,0,0,1,0,0,1,1,0,0,1,0,1,1,1,0,1,1,0,0,0,0,0,1,0,1,1,1,0,1,0,0,1,1,1,0,0,0,1,1,0,0,1,1,1,0,0,0,0,1,0,1,0,1,1,0,1,0,0,1,0,0,0,1,0,1,0,0,1,0,1,1],
                        [0,0,1,1,1,0,0,1,1,0,0,0,1,0,0,0,1,1,1,0,0,0,1,1,0,1,1,1,1,0,0,1,1,1,1,1,0,1,0,1,1,1,1,1,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,1,1,0,1,1,0,1,0,1,1,0,0,0,1,0,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,0,1,0,1,1,1,1,1,1,0,1,0,0,0,1,1,0,1,0,1,0,1,1,1,0,1,1,1,0,0,1,0,0,1,1,0,0,1,1,0,0,0,0,1,0,1,1,1,0,0,1,1,1,0,1,0,1,0,0,0,0,0,0,1,0,1,1,1,1,1,1,0,1,1,1,1,0,0,0,1,1,0,1,0,1,0,0,0,1,1,1,1,1,0,1,1,1,0,0,1,0,1,0,0,0,1,0,1,0,1,0,0,0,1,1,1,0,1,1,1,1,0,1,0,0,0,0,0,1,1,0,0,1,0,1,1,0,0,1,1,1,0,1,0,0,1,0,0,0,1,1,0,0,1,1,0,1,1,0,1,1,1,0,0,1,1,0,1,0,1,0,1,0,1,1,0,1,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,0,1,0,1,1,1,0,1,1,0,1,1,0,1,1,0,0,0,0,0,1,1,1,0,1,1,0,0,0,1,1,1,1,0,1,1,1,1,0,1,0,1,0,1,0,0,1,1,0,1,0,1,0,1,1,1,0,1,1,0,0,1,1,1,0,0,1,1,1,0,1,1,0,1,0,1,1,0,1,0,1,1,0,1,0,1,1,1,1,0,0,0,0,0,1,1,1,1,1,0,1,0,1,0,1,0,1,0,0,1,0,1,0,0,1,1,0,1,1,0,1,0,0,0,1,0,1,1,1,1,0,0,1,1,1,0,1,1,0,1,0,1,0,1,1,1,1,0,1,0,0,0,1,0,1,1,1,0,1,0,0,0,1,0,0,0,1,0,0,1,1,1,0,1,1,0,1,0,0,1,0,1,1,1,1,0,0,1,0,0,0,1,1,0,1,0,1,0,1,0,1,0,1,0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,1,0,0,0,1,0,1,1,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,1,0,1,1,1,0,0,1,0,1,1,1,0,1,0,0,0,1,1,1,1,0,0,1,1,0,1,1,0,0,0,0,0,0,0,1,1,0,1,1,0,1,0,0,0,0,0,1,1,0,1,0,1,0,0,0,1,0,0,1,1,0,0,0,0,0,0,1,0,1,1,1,0,0,1,0,0,1,0,1,1,1,0,1,1,1,1,0,0,1,1,1,0,0,0,0,0,1,1,1,0,1,1,0,1,0,1,0,1,0,1,0,1,1,0,0,0,0,1,0,1,0,1,0,1,1,0,0,0,1,0,0,1,1,0,0,1,1,0,0,0,0,1,0,0,0,1,1,0,1,1,0,0,0,0,0,1,0,1,1,0,0,0,1,1,0,1,0,1,0,0,0,0,0,1,0,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1,1,1,1,0,0,1,0,0,1,0,1,1,1,0,1,1,1,0,1,1,1,1,0,0,0,1,0,1,1,1,1,1,1,1,0,0,0,1,1,0,1,0,0,0,0,1,0,1,1,1,1,0,0,0,0,1,0,1,1,1,1,0,0,0,0,0],
                        [1,1,1,0,0,0,1,1,0,1,1,0,1,1,0,0,1,0,1,0,0,1,0,0,1,0,0,1,0,1,1,0,0,1,1,1,0,1,1,0,0,1,0,0,1,1,0,0,0,1,1,0,1,0,1,0,0,1,1,1,0,1,0,0,0,0,0,0,0,1,1,1,1,0,1,0,0,1,1,0,0,0,1,0,1,0,1,0,0,0,0,1,0,1,0,0,1,0,1,0,0,1,1,0,0,0,1,0,1,1,0,1,0,1,0,0,0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,0,1,0,1,0,1,0,0,1,1,1,0,1,1,1,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,1,1,0,0,1,1,1,1,1,0,1,1,0,1,1,0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,1,1,1,0,1,0,1,0,0,1,0,0,0,1,1,1,0,1,1,1,0,0,1,0,0,0,1,0,0,1,0,0,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,0,1,0,0,0,1,0,1,0,0,0,1,1,0,0,1,1,1,1,1,0,0,1,1,0,1,1,1,1,0,1,1,1,0,0,0,1,1,0,1,1,0,0,0,1,0,0,1,1,0,1,1,0,0,1,1,0,1,0,1,0,1,1,0,0,1,1,0,0,0,1,1,0,1,0,0,1,1,0,0,0,1,0,0,1,1,0,1,0,1,0,1,1,1,0,0,0,1,1,1,1,0,1,0,0,1,1,0,0,1,1,1,1,0,1,0,0,1,0,0,0,1,0,1,1,0,1,0,1,0,0,1,0,0,1,0,1,1,1,1,0,0,1,1,1,0,0,0,0,0,1,0,0,1,1,1,1,0,0,1,0,0,0,0,1,1,1,1,0,1,1,0,0,0,1,0,1,1,0,1,0,1,0,0,0,1,1,1,0,0,1,0,1,0,1,0,0,1,1,1,1,0,1,1,0,1,1,1,1,1,0,0,1,1,0,1,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,0,1,1,0,1,1,0,1,1,1,1,0,1,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1,1,1,0,1,1,1,0,1,0,1,0,1,1,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,1,0,0,0,0,1,1,1,0,0,0,1,1,0,1,1,0,0,1,1,0,1,1,1,0,0,1,1,0,1,1,0,1,0,0,0,1,1,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,1,0,1,0,0,1,1,1,0,1,0,1,1,0,1,1,0,1,1,0,0,0,0,1,1,0,0,0,0,0,1,0,1,1,1,1,0,1,0,0,0,1,1,1,1,1,0,0,1,0,1,1,0,0,0,0,1,0,1,1,0,0,0,0,0,1,0,0,1,1,1,1,0,0,0,1,0,1,1,0,0,1,0,1,0,0,1,1,1,0,1,1,0,1,1,0,0,1,0,0,0,1,1,1,0,0,0,0,0,1,0,1,1,1,1,0,1,1,1,0,0,1,1,1,0,0,0,1,0,1,1,1,1,0,1,1,0,0,1,1,0,0,0,1,1,0,1,1,0,1,0,0,0,1,1,0,0,1,0,0,0],
                        [1,0,1,1,0,0,1,0,0,0,1,1,1,1,1,1,1,0,0,1,1,0,1,0,1,1,0,0,1,1,0,0,1,0,0,1,0,1,0,1,0,1,0,1,1,1,0,0,1,0,1,0,0,1,1,1,0,1,1,0,1,0,1,0,0,1,1,0,1,0,1,0,0,1,1,0,0,1,1,1,0,1,1,0,0,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,0,1,1,0,1,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,1,1,0,0,0,1,0,0,1,1,1,0,1,1,0,0,1,1,0,0,1,0,0,1,0,1,1,1,1,0,1,0,0,0,0,1,1,0,1,1,1,0,1,0,1,1,0,0,1,0,1,1,1,0,1,0,1,1,0,0,1,1,1,0,0,1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,0,0,1,1,1,0,1,1,1,0,1,0,1,0,1,0,1,1,0,1,1,0,0,1,1,0,0,1,1,1,1,0,1,0,0,1,0,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,0,0,0,0,0,0,1,1,0,1,0,1,1,0,1,0,0,0,0,0,0,1,0,0,1,0,1,0,1,0,0,1,0,1,0,1,1,0,1,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,0,0,1,1,0,1,0,1,1,1,0,1,1,1,0,1,1,1,1,1,0,0,0,1,1,0,1,1,0,1,1,1,0,1,1,1,0,1,0,0,1,1,0,0,0,0,0,1,0,0,0,1,0,0,1,0,1,0,1,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,1,0,1,1,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,0,1,1,1,0,1,1,1,1,0,0,0,0,1,1,0,0,1,0,1,0,1,1,0,1,0,0,0,1,1,0,0,0,1,0,1,1,1,1,1,1,1,0,1,1,0,1,0,0,1,1,0,0,1,0,1,0,1,0,0,0,1,1,0,0,0,0,0,0,1,0,1,1,0,0,0,0,1,1,0,1,1,0,0,1,1,0,1,0,0,0,0,0,0,0,1,1,0,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,1,0,0,0,0,1,1,1,0,1,0,1,0,1,1,0,1,0,1,1,0,0,1,1,1,0,1,1,1,1,1,0,0,0,0,1,0,1,0,1,1,1,0,0,0,0,0,1,1,0,0,1,0,0,0,1,0,0,0,1,1,1,0,0,1,1,0,0,0,0,1,1,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,0,1,1,0,1,1,1,1,1,1,1,0,0,1,0,1,0,0,1,1,1,1,1,0,0,1,1,0,0,0,0,1,0,1,1,1,0,1,1,0,1,1,1,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,0,1,1,0,0,0,1,0,0,1,1,0,0,1,1,0,0,0,1,1,0,0,1,1,1,0,0,0,0,1,1,0,1,0,1,0,1,1,0,1,1,1,0,1,1,1,1,0,0,0,0,1,1,0,0,0,0,1,1,1,0,1,1,0,0,1,1,1,1,1,0,1,1,0,1,1,1,1,1,1,1,0,0,1,0,0,0,0,1,0,1,1,0,0,1,1,0,1,0,1,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,0,0,0,1,1],

]

class Network(object):
    def __init__(self):
        self.numPat = len(inputOutputDataset)
        self.numNeu = len(inputOutputDataset[0])
        self.numCycles = 0

        # set layers; there is not one for input because input doesn't have
        # a bias or previous layer to have connection with
        self.hopLayer = Layer(self.numNeu)

        self.setupWeights()

        for i in range(self.numPat):
            self.train(inputOutputDataset[i])

    #create matrix of weights
    def setupWeights(self):
        for i in range(self.numNeu):
            for x in range(self.numNeu):
                self.hopLayer.neurons[i].weights.append(0)

    # first, set weights and second, train the network by adding the weights; this stores the net
    def train(self, dataset):
        # set values for neurons
        for i in range(self.numNeu):
            self.hopLayer.neurons[i].value = dataset[i]

        # creates matrix for this set and add to previous matrix
        for i in range(self.numNeu):
            for x in range(self.numNeu):
                if i == x:
                    self.hopLayer.neurons[i].weights[x] += 0
                else:
                    self.hopLayer.neurons[i].weights[x] += ((2 * self.hopLayer.neurons[i].value - 1) *
                                                            (2 * self.hopLayer.neurons[x].value - 1))



    # turn setData into the inputOutputDataset
    def lookForSet(self, setData):
        cycles_rate = 500

        # set values for neurons
        for i in range(self.numNeu):
            self.hopLayer.neurons[i].value = setData[i]

        while(not self.hopLayer.haveAllNeuRun()): # keep running while all neurons have not updated at least once
            # neuron being updated
            self.numCycles += 1
            if self.numCycles % cycles_rate == 0:
                print("Cycle {0:d}".format(self.numCycles))
                for i in range(Hopfield.numNeu):
                    print("{0:d} ".format(self.getOutput(i)), end="")
                print()

            i = random.randint(0, self.numNeu - 1)
            # i = (i + (2*(random.randint(0, 2)) - 1)) % self.numNeu
            # i = (i + 2) % self.numNeu
            # Sum of weights of this neuron
            self.hopLayer.neurons[i].sum = 0
            for x in range(self.numNeu):
                if self.hopLayer.neurons[x].value == 1:
                    self.hopLayer.neurons[i].sum += self.hopLayer.neurons[i].weights[x] #* (2 * self.hopLayer.neurons[x].value - 1) #test

            # check to see if it fires or not
            self.hopLayer.neurons[i].thresholdFunc()

            if self.hopLayer.hasANeuChanged():
                self.hopLayer.resetRunAndChange()

    def getOutput(self, index):
        return self.hopLayer.neurons[index].value

Hopfield = Network()
input = \
[0,1,1,1,1,0,0,0,1,0,0,0,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,0,0,0,0,0,1,0,1,1,1,1,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,0,0,0,1,1,0,0,1,0,1,1,0,1,1,1,0,0,1,1,1,1,0,0,0,0,0,1,1,0,0,0,0,1,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,0,0,0,0,1,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,1,0,1,0,1,1,0,0,1,0,0,0,0,0,1,1,1,1,1,1,0,0,1,1,1,1,0,1,0,1,0,0,1,0,0,0,0,1,1,0,0,0,1,1,1,0,1,0,1,0,1,0,0,0,1,1,0,1,1,1,0,0,0,1,0,0,0,1,1,0,1,1,0,1,0,0,0,0,0,1,1,0,1,0,0,0,1,1,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,1,1,1,0,0,0,1,0,0,1,1,0,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,0,1,0,0,1,0,0,1,1,1,0,0,1,1,1,1,0,0,1,1,0,1,0,1,1,1,0,1,0,0,1,0,1,0,1,0,0,0,1,0,0,1,0,0,0,1,0,1,1,1,0,0,0,0,1,1,1,0,0,0,0,1,0,1,0,0,0,0,1,0,1,1,0,1,0,1,0,1,0,0,0,0,1,1,0,1,0,1,1,0,1,1,0,1,0,1,0,1,1,0,1,0,1,0,1,1,0,0,0,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,1,0,1,0,1,1,0,1,1,1,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0,1,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,1,0,0,0,1,0,1,0,0,1,1,1,1,0,1,1,1,1,0,0,1,1,1,0,0,0,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,0,1,1,1,0,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,0,1,0,1,0,0,1,0,0,1,1,1,0,0,1,1,0,1,1,0,0,0,0,1,0,1,0,1,0,0,1,1,1,0,0,0,0,1,1,0,1,0,1,0,0,1,1,1,0,1,0,1,1,0,1,1,1,1,0,1,0,1,0,1,1,0,0,0,1,1,0,0,0,0,1,0,0,0,1,1,1,0,1,0,0,1,0,1,1,1,0,0,1,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,0,1,0,0,0,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,1,1,0,0,1,0,1,0,1,0,1,1,0,0,1,1,0,0,1,1,0,1,0,1,1,1,1,1,1,0,0,0,1,0,0,0,0,0,1,0,1,0,0,1,1,1,0,0,0,0,0,0,1,0,0,0,1,1,0,1,0,0,1,1,1,1,0,1,1,1,0,0,1,1,0,0,1,0,0,1,0,1,1,0,0,1,1,0,0,0,1,1,0,1,1,0,1,0,0,0,1,1,0,0,1,0,0,0]
#[0,1,1,1,1,0,0,0,1,0,0,0,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,0,0,0,0,0,1,0,1,1,1,1,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,1,1,0,0,1,1,1,1,1,1,1,0,0,0,1,1,0,0,1,0,1,1,0,1,1,1,0,0,1,1,1,1,0,0,0,0,0,1,1,0,0,0,0,1,0,1,1,1,0,1,1,1,1,0,1,0,0,1,1,0,0,0,0,1,0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0,1,0,1,0,1,1,0,0,1,0,0,0,0,0,1,1,1,1,1,1,0,0,1,1,1,1,0,1,0,1,0,0,1,0,0,0,0,1,1,0,0,0,1,1,1,0,1,0,1,0,1,0,0,0,1,1,0,1,1,1,0,0,0,1,0,0,0,1,1,0,1,1,0,1,0,0,0,0,0,1,1,0,1,0,0,0,1,1,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,1,1,1,0,0,0,1,0,0,1,1,0,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,0,1,0,0,1,0,0,1,1,1,0,0,1,1,1,1,0,0,1,1,0,1,0,1,1,1,0,1,0,0,1,0,1,0,1,0,0,0,1,0,0,1,0,0,0,1,0,1,1,1,0,0,0,0,1,1,1,0,0,0,0,1,0,1,0,0,0,0,1,0,1,1,0,1,0,1,0,1,0,0,0,0,1,1,0,1,0,1,1,0,1,1,0,1,0,1,0,1,1,0,1,0,1,0,1,1,0,0,0,0,1,0,1,0,0,1,0,1,0,0,1,1,1,1,1,1,0,1,0,1,1,0,1,1,1,0,0,0,1,1,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0,1,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,1,0,0,0,1,0,1,0,0,1,1,1,1,0,1,1,1,1,0,0,1,1,1,0,0,0,1,1,1,1,0,1,0,1,1,1,0,1,1,1,1,0,1,1,1,0,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,0,0,1,0,1,0,1,0,1,0,0,1,0,0,1,1,1,0,0,1,1,0,1,1,0,0,0,0,1,0,1,0,1,0,0,1,1,1,0,0,0,0,1,1,0,1,0,1,0,0,1,1,1,0,1,0,1,1,0,1,1,1,1,0,1,0,1,0,1,1,0,0,0,1,1,0,0,0,0,1,0,0,0,1,1,1,0,1,0,0,1,0,1,1,1,0,0,1,0,0,0,0,0,0,0,1,1,1,1,1,1,0,0,1,1,0,1,1,1,1,1,1,1,0,1,1,0,1,0,1,0,0,0,1,1,1,1,1,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,1,1,0,0,1,0,1,0,1,0,1,1,0,0,1,1,0,0,1,1,0,1,0,1,1,1,1,1,1,0,0,0,1,0,0,0,0,0,1,0,1,0,0,1,1,1,0,0,0,0,0,0,1,0,0,0,1,1,0,1,0,0,1,1,1,1,0,1,1,1,0,0,1,1,0,0,1,0,0,1,1,1,1,0,0,1,0,1,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,1,1,1,0]
#[1,1,1,0,0,0,1,1,0,1,1,0,1,1,0,0,1,0,1,0,0,1,0,0,1,0,0,1,0,1,1,0,0,1,1,1,0,1,1,0,0,1,0,0,1,1,0,0,0,1,1,0,1,0,1,0,0,1,1,1,0,1,0,0,0,0,0,0,0,1,1,1,1,0,1,0,0,1,1,0,0,0,1,0,1,0,1,0,0,0,0,1,0,1,0,0,1,0,1,0,0,1,1,0,0,0,1,0,1,1,0,1,0,1,0,0,0,0,0,1,1,0,0,1,1,0,0,1,0,1,0,0,1,0,1,0,1,0,0,1,1,1,0,1,1,1,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,1,1,0,0,1,1,1,1,1,0,1,1,0,1,1,0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,1,1,1,0,1,0,1,0,0,1,0,0,0,1,1,1,0,1,1,1,0,0,1,0,0,0,1,0,0,1,0,0,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,0,1,0,0,0,1,0,1,0,0,0,1,1,0,0,1,1,1,1,1,0,0,1,1,0,1,1,1,1,0,1,1,1,0,0,0,1,1,0,1,1,0,0,0,1,0,0,1,1,0,1,1,0,0,1,1,0,1,0,1,0,1,1,0,0,1,1,0,0,0,1,1,0,1,0,0,1,1,0,0,0,1,0,0,1,1,0,1,0,1,0,1,1,1,0,0,0,1,1,1,1,0,1,0,0,1,1,0,0,1,1,1,1,0,1,0,0,1,0,0,0,1,0,1,1,0,1,0,1,0,0,1,0,0,1,0,1,1,1,1,0,0,1,1,1,0,0,0,0,0,1,0,0,1,1,1,1,0,0,1,0,0,0,0,1,1,1,1,0,1,1,0,0,0,1,0,1,1,0,1,0,1,0,0,0,1,1,1,0,0,1,0,1,0,1,0,0,1,1,1,1,0,1,1,0,1,1,1,1,1,0,0,1,1,0,1,0,1,0,0,0,1,0,0,1,0,1,0,0,1,1,0,0,1,1,0,1,1,0,1,1,1,1,0,1,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1,1,1,0,1,1,1,0,1,0,1,0,1,1,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,1,0,0,0,0,1,1,1,0,0,0,1,1,0,1,1,0,0,1,1,0,1,1,1,0,0,1,1,0,1,1,0,1,0,0,0,1,1,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1,0,1,0,1,0,0,1,1,1,0,1,0,1,1,0,1,1,0,1,1,0,0,0,0,1,1,0,0,0,0,0,1,0,1,1,1,1,0,1,0,0,0,1,1,1,1,1,0,0,1,0,1,1,0,0,0,0,1,0,1,1,0,0,0,0,0,1,0,0,1,1,1,1,0,0,0,1,0,1,1,0,0,1,0,1,0,0,1,1,1,0,1,1,0,1,1,0,0,1,0,0,0,1,1,1,0,0,0,0,0,1,0,1,1,1,1,0,1,1,1,0,0,1,1,1,0,0,0,1,0,1,1,1,1,0,1,1,0,0,1,1,0,0,0,1,1,0,1,1,0,1,0,0,0,1,1,0,0,1,0,0,0]
#[1,1,0,0,0,1,1,1, 0,1,0,1,0,1,0,1, 1,1,0,0,1,1,0,1, 1,0,1,1,0,0,1,0, 1,1,1,1,0,0,1,1, 1,1,1,1,1,0,0,0, 1,1,1,0,1,0,0,0, 1,0,1,1,1,0,1,1, 1,1,0,1,1,0,1,1, 1,0,0,0,0,1,0,0]
#input = [0, 1, 0, 1, 1] #- test

Hopfield.lookForSet(input)

#print("********  Matrix  ********")
#for i in range(Hopfield.numNeu):
#    for x in range(Hopfield.numNeu):
#        print("{0:2d}".format(Hopfield.hopLayer.neurons[i].weights[x]), end=" ")
#    print()

print("*****  Training set  *****")
for i in range(Hopfield.numPat):
    for x in range(Hopfield.numNeu):
        print("{0:d}".format(inputOutputDataset[i][x]), end=" ")
    print()

print("*******  Input set  *******")
for i in range(len(input)):
    print("{0:d} ".format(input[i]), end="")
print()

print("********  Results  ********")
for i in range(Hopfield.numNeu):
    print("{0:d} ".format(Hopfield.getOutput(i)), end="")
print()


